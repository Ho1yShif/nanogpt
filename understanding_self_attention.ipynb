{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Self-Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10488bcb0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Download Shakespeare training dataset'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Download Shakespeare training dataset\"\"\"\n",
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Read Shakespeare file\"\"\"\n",
    "with open('input.txt', 'r', encoding='utf-8') as file:\n",
    "\ttext = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Trick in Self-Attention\n",
    "- We want each of the 8 tokens in the T vector (time) to communicate with each other in a specific way\n",
    "- Specifically, we want each token to communicate with the tokens that come before it, and not those that come after it\n",
    "- This way, information only flows from previous context to the current timestamp, and not the other way around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, time, channels = 4, 8, 2\n",
    "x = torch.randn(batch, time, channels)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want x[batch, time] = mean_{idx <= t} x [batch, idx]\n",
    "- There's a word stored at each of the 8 time locations\n",
    "- `Bag-of-words` is an expression for averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bag_of_words = torch.zeros((batch, time, channels))\n",
    "\n",
    "for b in range(batch):\n",
    "\tfor t in range(time):\n",
    "\t\tx_prev = x[b, :t+1]\n",
    "\t\tx_bag_of_words[b, t] = torch.mean(x_prev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"0th batch element\"\"\"\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"First batch element is the same as the above because it's just the average of the first element,\n",
    "but the second element is the average of elements one and two, and so on\n",
    "\"\"\"\n",
    "x_bag_of_words[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Matrix Multiplication\n",
    "Version 1\n",
    "- For every T-th token, we want to calculate the average of all the vectors in all previous tokens and the current token\n",
    "- Unfortunately, this process is very inefficient. The trick is to increase the efficiency by using matrix multiplication\n",
    "- Â In the code below, Matrix c is essentially a running sum of matrix b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[ 2.,  7.],\n",
      "        [ 8., 11.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Toy example illustrating how matrix multiplication can be used for a 'weighted aggregation'\"\"\"\n",
    "torch.manual_seed(42)\n",
    "\"\"\"\n",
    "Tril returns the lower left triangular part of a matrix and zeros out the upper triangle\n",
    "Tril allows us to just pick out exact numbers from matrix b and keep them in the resulting matrix c\n",
    "\"\"\"\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "\"\"\"@ is shorthand for matrix multiplication\"\"\"\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once we apply the following line to matrix a, `a = a / torch.sum(a, 1, keepdim=True)`, we get a running _average_ instead of a running sum\n",
    "- This allows us to calculate the running incremental average of all the vectors in all previous tokens and the current token much more efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Toy example illustrating how matrix multiplication can be used for a 'weighted aggregation'\"\"\"\n",
    "torch.manual_seed(42)\n",
    "\"\"\"\n",
    "Tril returns the lower left triangular part of a matrix and zeros out the upper triangle\n",
    "Tril allows us to just pick out exact numbers from matrix b and keep them in the resulting matrix c\n",
    "\"\"\"\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "\"\"\"Keepdim ensures that the sum has the same dimensions as the original tensor\"\"\"\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "\"\"\"Now each row in matrix a will sum to 1\"\"\"\n",
    "\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "\"\"\"@ is shorthand for matrix multiplication\"\"\"\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreating X-Bag-of-Words Using a Weights Matrix\n",
    "Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Weights represent how much of every row we want to average\"\"\"\n",
    "weights = torch.tril(torch.ones(time, time))\n",
    "\"\"\"Normalize the weights so that each row sums to 1\"\"\"\"\"\n",
    "weights = weights / weights.sum(1, keepdim=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PyTorch Matrix Multiplication\n",
    "By default, you can't multiply (T, T) @ (B, T, C)\n",
    "To make this feasible, PyTorch will add a batch dimension to the first matrix so that the final dimensions look like this:\n",
    "(B, T, T) @ (B, T, C)\n",
    "This is a batched matrix multiply, so the matrix multiplication will be applied to each batch in parallel\n",
    "The result will be a (B, T, C) matrix\n",
    "\"\"\"\n",
    "x_bag_of_words_2 = weights @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "`torch.allclose` returns True if all elements of two tensors are equal within a certain tolerance\n",
    "Essentially, the matrix multiplication by the weights just made x_bag_of_words_2 equal to x_bag_of_words\n",
    "\"\"\"\n",
    "torch.allclose(x_bag_of_words, x_bag_of_words_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]]),\n",
       " tensor([[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Visualize the first elements of each tensor to show they're equal\"\"\"\n",
    "x_bag_of_words[0], x_bag_of_words_2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: Weights Matrix Method\n",
    "- We used batched matrix multiplication to perform a weighted aggregation\n",
    "- We took weighted sums using the weighted vector which takes on a triangular form\n",
    "- The triangular form means that each token at the T-th dimension only gets information from the tokens preceding it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "Version 3 <br><br>\n",
    "As a review, Softmax converts a vector of numbers into a probability distribution. <br>\n",
    "It does this by taking the exponential of each element in the vector,\n",
    "then dividing each result by the sum of these exponentials. <br>\n",
    "This ensures that the output values are between 0 and 1 and sum to 1,\n",
    "making them interpretable as probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initialize weights vector to all zeros and tril vector to all ones\"\"\"\n",
    "weights = torch.zeros((time, time))\n",
    "tril = torch.tril(torch.ones((time, time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Everywhere that tril == 0, replace the weights value with a value of negative infinity\"\"\"\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Take a Softmax normalization along every row\n",
    "The negative infinity values become zeroes;\n",
    "Other values will then be normalized to sum to 1\n",
    "\"\"\"\n",
    "weights = F.softmax(weights, dim=1)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"We can then create the same bag of words representation as before using matrix multiplication\"\"\"\n",
    "x_bag_of_words_3 = weights @ x\n",
    "torch.allclose(x_bag_of_words, x_bag_of_words_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: Softmax Method\n",
    "- This is helpful for self-attention because all the weights begin with 0\n",
    "- This 0 represents the interaction strength or affinity between tokens; it tells us how much of each past token to aggregate\n",
    "- The masked fill tells future tokens that they cannot communicate with the past by setting those values to negative infinity\n",
    "- Then the matrix goes through softmax and aggregation via matrix multiplication\n",
    "- In practical applications, the affinities won't be at 0. They will be data dependent; some tokens will find other tokens more or less interesting\n",
    "- We'll use the word `Affinity` to describe the interest one token takes in another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "- A lower triangular matrix is used to perform a weighted aggregation of past elements\n",
    "- The lower half of the triangular matrix tells us how much of each element fuses into the current position\n",
    "\t- In other words, how information from previous elements is combined into the current element based on the weights specified in the lower triangular matrix\n",
    "- This allows us to calculate the running incremental average of all the vectors in all previous tokens and the current token much more efficiently\n",
    "- By using batched matrix multiplication, we can perform this weighted aggregation in parallel for each batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Attention\n",
    "Version 4\n",
    "- Implement small self attention for a single head\n",
    "- Problem solved by self-attention: Need to gather data from the past in a data-dependent way\n",
    "- Solution\n",
    "\t- Every token emits 2 vectors: a query vector and a key vector\n",
    "\t- Query vector tells you what you're looking for\n",
    "\t- Key vectors tells you what you're obtaining\n",
    "\t- Calculate the affinity between tokens by taking the dot product between key and query vectors\n",
    "\t- One query dot product with all the keys of the other tokens, which becomes the weights vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, time, channels = 4, 8, 32\n",
    "x = torch.randn(batch, time, channels)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"input is divided into a number of heads to capture\n",
    "different types of information\"\"\"\n",
    "head_size = 16\n",
    "\"\"\"\n",
    "Create linear transformations (fully connected layer) for the keys and queries\n",
    "in the attention mechanism. The input size is `channels` and the output size is\n",
    "`head_size`.\n",
    "The `bias=False` means that no bias term is added in this linear transformation.\n",
    "\"\"\"\n",
    "key = nn.Linear(channels, head_size, bias=False)\n",
    "query = nn.Linear(channels, head_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apply linear transformations to the input tensor `x` by forwarding it through\n",
    "The sizes will be influenced by the head size\n",
    "k and q will be (batch, time, 16)\n",
    "\"\"\"\n",
    "k = key(x)\n",
    "q = query(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now, we set weights using the communication between the keys and queries\n",
    "Don't forget to transpose the last two dimensions of the keys so that the matrix multiplication works\n",
    "Weights dimensions will be (batch, time, time)\n",
    "Instead of 0s like before, the weights are the affinities between the keys and queries vectors\n",
    "This solves the data-dependent computation problem\n",
    "\"\"\"\n",
    "weights = q @ k.transpose(-2, -1)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(time, time))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "out = weights @ x\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.7398, 0.2602, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1925, 0.5954, 0.2121, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0614, 0.0158, 0.1812, 0.7417, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3992, 0.1295, 0.1087, 0.0681, 0.2946, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0100, 0.0046, 0.0320, 0.4386, 0.0850, 0.4299, 0.0000, 0.0000],\n",
       "         [0.1534, 0.1392, 0.3999, 0.0747, 0.0853, 0.0974, 0.0501, 0.0000],\n",
       "         [0.2058, 0.1392, 0.2022, 0.0859, 0.2243, 0.0133, 0.0356, 0.0936]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1611, 0.8389, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4854, 0.1379, 0.3767, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0936, 0.3291, 0.5142, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1606, 0.6707, 0.1167, 0.0268, 0.0252, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1349, 0.4268, 0.1234, 0.0833, 0.1074, 0.1242, 0.0000, 0.0000],\n",
       "         [0.0221, 0.4049, 0.0609, 0.3434, 0.0767, 0.0543, 0.0376, 0.0000],\n",
       "         [0.0294, 0.0160, 0.3545, 0.0545, 0.0406, 0.0960, 0.3236, 0.0856]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0229, 0.9771, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1941, 0.6315, 0.1744, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0560, 0.3426, 0.5631, 0.0383, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1100, 0.3809, 0.1208, 0.2041, 0.1842, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4430, 0.0351, 0.1528, 0.0502, 0.2646, 0.0543, 0.0000, 0.0000],\n",
       "         [0.2119, 0.0699, 0.2232, 0.0282, 0.1831, 0.1944, 0.0893, 0.0000],\n",
       "         [0.2765, 0.0173, 0.1410, 0.0594, 0.2014, 0.0636, 0.1763, 0.0645]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.7687, 0.2313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.8431, 0.1088, 0.0481, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0706, 0.4582, 0.3035, 0.1677, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0404, 0.0506, 0.2432, 0.2024, 0.4633, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0279, 0.0153, 0.0333, 0.2878, 0.4402, 0.1956, 0.0000, 0.0000],\n",
       "         [0.0129, 0.0324, 0.0087, 0.0193, 0.1081, 0.0147, 0.8040, 0.0000],\n",
       "         [0.0362, 0.8456, 0.0228, 0.0098, 0.0229, 0.0249, 0.0276, 0.0101]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Weights are now data-independent and can be used to capture the relationship between the keys and queries\n",
    "Therefore, each batch element will now have a different set of weights\n",
    "\"\"\"\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
